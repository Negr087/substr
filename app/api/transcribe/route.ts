import { NextRequest, NextResponse } from 'next/server';

export async function OPTIONS() {
  return new NextResponse(null, {
    headers: {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'POST, OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type',
    },
  });
}

// Funci√≥n para traducir texto a espa√±ol
async function translateToSpanish(text: string): Promise<string> {
  try {
    const response = await fetch(
      'https://api-inference.huggingface.co/models/Helsinki-NLP/opus-mt-en-es',
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.HUGGINGFACE_API_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ inputs: text }),
      }
    );

    if (!response.ok) {
      console.error('‚ùå Error en traducci√≥n');
      return text; // Devolver texto original si falla
    }

    const result = await response.json();
    return result[0]?.translation_text || text;
  } catch (error) {
    console.error('‚ùå Error traduciendo:', error);
    return text; // Devolver texto original si falla
  }
}

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;

    if (!audioFile) {
      return NextResponse.json(
        { error: 'No se proporcion√≥ archivo de audio' },
        { status: 400 }
      );
    }

    console.log('üéôÔ∏è Transcribiendo audio...', audioFile.size, 'bytes');
    const audioBuffer = await audioFile.arrayBuffer();

    // Paso 1: Transcribir audio con Whisper
    const transcriptionResponse = await fetch(
      'https://api-inference.huggingface.co/models/openai/whisper-large-v3',
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.HUGGINGFACE_API_KEY}`,
          'Content-Type': 'audio/webm',
        },
        body: audioBuffer,
      }
    );

    if (!transcriptionResponse.ok) {
      const errorText = await transcriptionResponse.text();
      console.error('‚ùå Error de Hugging Face:', errorText);
      throw new Error(`API error: ${transcriptionResponse.status} - ${errorText}`);
    }

    const transcriptionResult = await transcriptionResponse.json();
    console.log('‚úÖ Transcripci√≥n completada');

    // Paso 2: Traducir cada segmento a espa√±ol
    const segments = transcriptionResult.chunks || [{ timestamp: [0], text: transcriptionResult.text }];
    
    const translatedSegments = await Promise.all(
      segments.map(async (chunk: any) => {
        const translatedText = await translateToSpanish(chunk.text);
        console.log(`üåê "${chunk.text}" ‚Üí "${translatedText}"`);
        return {
          start: chunk.timestamp[0],
          text: translatedText
        };
      })
    );

    const responseData = {
      text: translatedSegments.map(s => s.text).join(' '),
      segments: translatedSegments
    };

    return NextResponse.json(responseData);

  } catch (error: any) {
    console.error('‚ùå Error completo:', error);
    return NextResponse.json(
      { error: 'Error al procesar el audio', details: error.message },
      { status: 500 }
    );
  }
}